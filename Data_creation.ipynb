{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5f2f2546-e956-4b7e-b5ef-002b7d86182d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Enter the name of the Person:  sachin\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collected Face 1\n",
      "Collected Face 2\n",
      "Collected Face 3\n",
      "Collected Face 4\n",
      "Collected Face 5\n",
      "Collected Face 6\n",
      "Collected Face 7\n",
      "Collected Face 8\n",
      "Collected Face 9\n",
      "Collected Face 10\n",
      "Collected Face 11\n",
      "Collected Face 12\n",
      "Collected Face 13\n",
      "Collected Face 14\n",
      "Collected Face 15\n",
      "Collected Face 16\n",
      "Collected Face 17\n",
      "Collected Face 18\n",
      "Collected Face 19\n",
      "Collected Face 20\n",
      "Collected Face 21\n",
      "Collected Face 22\n",
      "Collected Face 23\n",
      "Collected Face 24\n",
      "Collected Face 25\n",
      "Collected Face 26\n",
      "Collected Face 27\n",
      "Collected Face 28\n",
      "Collected Face 29\n",
      "Collected Face 30\n",
      "Collected Face 31\n",
      "Collected Face 32\n",
      "Collected Face 33\n",
      "Collected Face 34\n",
      "Collected Face 35\n",
      "Collected Face 36\n",
      "Collected Face 37\n",
      "Collected Face 38\n",
      "Collected Face 39\n",
      "Collected Face 40\n",
      "Collected Face 41\n",
      "Data successfully saved at ./data/sachin.npy\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "# Initialize the video capture object\n",
    "cap = cv2.VideoCapture(0)\n",
    "\n",
    "# Load the face cascade classifier\n",
    "face_cascade = cv2.CascadeClassifier(\"haarcascade_frontalface_alt.xml\")\n",
    "\n",
    "skip = 0\n",
    "face_data = []\n",
    "dataset_path = './data/'\n",
    "\n",
    "# Ask for the name of the person whose data is being collected\n",
    "file_name = input(\"Enter the name of the Person: \")\n",
    "\n",
    "# Create a folder for saving the collected face data if it doesn't exist\n",
    "if not os.path.exists(dataset_path):\n",
    "    os.makedirs(dataset_path)\n",
    "\n",
    "while True:\n",
    "    ret, frame = cap.read()\n",
    "\n",
    "    if not ret:\n",
    "        continue\n",
    "    \n",
    "    # Convert the frame to grayscale for face detection\n",
    "    gray_frame = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "    \n",
    "    # Detect faces in the frame\n",
    "    faces = face_cascade.detectMultiScale(gray_frame, 1.3, 5)\n",
    "    \n",
    "    # Sort the faces based on the area (largest face first)\n",
    "    faces = sorted(faces, key=lambda f: f[2] * f[3], reverse=True)\n",
    "    \n",
    "    # Pick the largest face and save its data\n",
    "    for face in faces[:1]:  # Process only the largest face detected\n",
    "        x, y, w, h = face\n",
    "        offset = 10  # Adding padding to the face region\n",
    "        \n",
    "        # Extract (Crop) the required face region\n",
    "        face_section = frame[y - offset:y + h + offset, x - offset:x + w + offset]\n",
    "        face_section = cv2.resize(face_section, (100, 100))\n",
    "\n",
    "        skip += 1\n",
    "        \n",
    "        # Store every 10th face to reduce redundancy\n",
    "        if skip % 10 == 0:\n",
    "            face_data.append(face_section)\n",
    "            print(f\"Collected Face {len(face_data)}\")\n",
    "\n",
    "        # Draw a rectangle around the face\n",
    "        cv2.rectangle(frame, (x - offset, y - offset), (x + w + offset, y + h + offset), (255, 0, 0), 2)\n",
    "    \n",
    "    # Display the frame with the rectangle drawn\n",
    "    cv2.imshow(\"Collecting Face Data\", frame)\n",
    "    \n",
    "    # Check if the 'q' key was pressed to exit the loop\n",
    "    key_pressed = cv2.waitKey(1) & 0xFF\n",
    "    if key_pressed == ord('q'):\n",
    "        break\n",
    "\n",
    "# Convert face data into a numpy array\n",
    "face_data = np.asarray(face_data)\n",
    "face_data = face_data.reshape((face_data.shape[0], -1))\n",
    "\n",
    "# Save the face data as a .npy file\n",
    "np.save(os.path.join(dataset_path, file_name + '.npy'), face_data)\n",
    "print(f\"Data successfully saved at {dataset_path}{file_name}.npy\")\n",
    "\n",
    "# Release the video capture object and close all OpenCV windows\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a81aa9e8-78bd-4914-9996-fc9808ae1b8c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
